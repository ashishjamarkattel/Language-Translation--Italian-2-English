{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a363ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTMCell, LSTM, Input, RNN, Activation, add, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9759c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi.\tCiao!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #607364 (Cero)\n",
      "\n",
      "Hi.\tCiao.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4522287 (Guybrush88)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = \"ita.txt\" ## contains the italian to english \n",
    "#visulaizing sample of ita.txt\n",
    "with open(data,\"r\") as f:\n",
    "    print(f.readline())\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4b938",
   "metadata": {},
   "source": [
    "<pre><b>Observation:</b>\n",
    "\n",
    "contains the english and italian with some copyrights\n",
    "seperated by tabs</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1caeabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class process_data:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.english = []\n",
    "        self.italian = []\n",
    "        \n",
    "    def readFile(self):\n",
    "        \n",
    "        with open(self.data,errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                eng,ita,cc = line.split(\"\\t\")\n",
    "                self.english.append(eng)\n",
    "                self.italian.append(ita)\n",
    "                \n",
    "        data = pd.DataFrame({\n",
    "            \"english\": self.english,\n",
    "            \"italian\": self.italian\n",
    "        })\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    def cleanText(self,data):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function removes:\n",
    "        1. Numbers in the data.\n",
    "        2. special characters.\n",
    "        3. lowers the data.\n",
    "        4. remove extra spaces if any.\n",
    "        \"\"\"\n",
    "        \n",
    "        data = data.lower()      ## lowers the text\n",
    "        data = re.sub(\"[^A-Za-z0-9]+\",\" \",data) ## remove special character expect number and charcter\n",
    "        data = re.sub(\"[0-9]\",\" \",data)\n",
    "        data = \" \".join(data.split(\" \")) ## removes extra spaces if any\n",
    "        return data\n",
    "    \n",
    "    def main(self):\n",
    "        \n",
    "        data = self.readFile()\n",
    "        data[\"processed_english\"] = data[\"english\"].apply(self.cleanText)\n",
    "        data[\"processed_italian\"] = data[\"italian\"].apply(self.cleanText)\n",
    "        data.drop(columns=[\"english\",\"italian\"],inplace=True)\n",
    "        \n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0acc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to process:  0:00:10.271851\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_english</th>\n",
       "      <th>processed_italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268954</th>\n",
       "      <td>i want you to stay here with her</td>\n",
       "      <td>voglio che tu stia qui con lei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94691</th>\n",
       "      <td>there s little to do</td>\n",
       "      <td>c poco da fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348748</th>\n",
       "      <td>she came to my defence when i was accused of p...</td>\n",
       "      <td>lei venuta in mia difesa quando sono stata acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213269</th>\n",
       "      <td>he can play tennis very well</td>\n",
       "      <td>sa giocare a tennis molto bene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>i got angry</td>\n",
       "      <td>mi sono arrabbiato</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        processed_english  \\\n",
       "268954                  i want you to stay here with her    \n",
       "94691                               there s little to do    \n",
       "348748  she came to my defence when i was accused of p...   \n",
       "213269                      he can play tennis very well    \n",
       "4988                                         i got angry    \n",
       "\n",
       "                                        processed_italian  \n",
       "268954                    voglio che tu stia qui con lei   \n",
       "94691                                     c poco da fare   \n",
       "348748  lei venuta in mia difesa quando sono stata acc...  \n",
       "213269                    sa giocare a tennis molto bene   \n",
       "4988                                  mi sono arrabbiato   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "data = process_data(\"ita.txt\").main()\n",
    "print(\"Total time taken to process: \",datetime.now()-start_time)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87373db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,\"processed_italian\"] = \"<start> \" + data[\"processed_italian\"]+\" <end>\"\n",
    "data[\"decoder_input\"] = \"<start> \"+ data[\"processed_english\"]\n",
    "data[\"decoder_output\"] = data[\"processed_english\"]+\" <end>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6bbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping the processed_english\n",
    "data.drop(columns=[\"processed_english\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the one <end> in the decoder input for the tokenization\n",
    "data.iloc[0][\"decoder_input\"] = data.iloc[0][\"decoder_input\"] + \" <end>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd526b6",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb691b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(data,shuffle=True,test_size=0.2)\n",
    "df_train,df_cv = train_test_split(df_train,shuffle=True,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81363144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Train : \",df_train.shape[0])\n",
    "print(f\"Shape of CV : {df_cv.shape[0]}\")\n",
    "print(f\"Shape of Test : {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111cf91",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0dc165",
   "metadata": {},
   "source": [
    "##### Encoder inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdc9c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_encoder = Tokenizer(filters=\"\",oov_token = 'UNK')\n",
    "tokenizer_encoder.fit_on_texts(df_train[\"processed_italian\"])\n",
    "encoder_input_train = tokenizer_encoder.texts_to_sequences(df_train[\"processed_italian\"])\n",
    "encoder_input_cv = tokenizer_encoder.texts_to_sequences(df_cv[\"processed_italian\"])\n",
    "encoder_word_to_int = tokenizer_encoder.word_index\n",
    "encoder_vocab_size = len(encoder_word_to_int)+1 ## used in embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Decoder Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20c8523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_decoder = Tokenizer(filters=\"\",oov_token=\"UNK\")\n",
    "tokenizer_decoder.fit_on_texts(df_train[\"decoder_input\"])\n",
    "## for decoder input\n",
    "decoder_input_train = tokenizer_decoder.texts_to_sequences(df_train[\"decoder_input\"])\n",
    "decoder_input_cv = tokenizer_decoder.texts_to_sequences(df_cv[\"decoder_input\"])\n",
    "## for decoder output\n",
    "decoder_output_train = tokenizer_decoder.texts_to_sequences(df_train[\"decoder_output\"])\n",
    "decoder_output_cv = tokenizer_decoder.texts_to_sequences(df_cv[\"decoder_output\"])\n",
    "decoder_word_to_int = tokenizer_decoder.word_index\n",
    "decoder_vocab_size = len(decoder_word_to_int)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e0fcac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the optimal length for padding\n",
    "count = data[\"processed_italian\"].apply(lambda x:len(x.split(\" \")))\n",
    "plt.figure(figsize=(16,6))\n",
    "c = sns.countplot(count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed89d4",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "<pre>\n",
    "20 seems favourable for padding\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4fdb64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data, max_len=20):\n",
    "\n",
    "    return pad_sequences(data,\n",
    "                         maxlen=max_len,\n",
    "                         padding='post',\n",
    "                         truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d16e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## encoder\n",
    "encoder_input_train = padding(encoder_input_train)\n",
    "encoder_input_cv = padding(encoder_input_cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2cac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_train = padding(decoder_input_train)\n",
    "decoder_input_cv = padding(decoder_input_cv)\n",
    "## for output decoder\n",
    "decoder_output_train = padding(decoder_output_train)\n",
    "decoder_output_cv = padding(decoder_output_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eefac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of encoder input: \",encoder_input_train.shape)\n",
    "print(\"Shape of decoder input: \",decoder_input_train.shape)\n",
    "print(\"Shape of decoder output: \",decoder_output_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "410889a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataLoader(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self,encoder_input,decoder_input,decoder_output,batch):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.decoder_output = decoder_output\n",
    "        self.batch_size = batch\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        start = i * self.batch_size\n",
    "        end = (i+1) * self.batch_size\n",
    "        encoder = []\n",
    "        decoder_input = []\n",
    "        decoder_output = []\n",
    "        for i in range(start,end):\n",
    "            encoder.append(self.encoder_input[i])\n",
    "            decoder_input.append(self.decoder_input[i])\n",
    "            decoder_output.append(self.decoder_output[i])\n",
    "            \n",
    "        return [np.array(encoder),np.array(decoder_input)],np.array(decoder_output)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoder_input)//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b2f58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 inp_vocab_size,\n",
    "                 embedding_size,\n",
    "                 lstm_size,\n",
    "                 input_length):\n",
    "\n",
    "        super().__init__()\n",
    "        #Embedding layer\n",
    "        self.embedding = Embedding(inp_vocab_size, embedding_size, input_length = input_length)\n",
    "        # Encoder LSTM layer\n",
    "        self.lstm_size = lstm_size\n",
    "        lstmcell = LSTMCell(lstm_size)\n",
    "        self.lstm = RNN(lstmcell, return_sequences = True, return_state = True)\n",
    "\n",
    "\n",
    "    def call(self,\n",
    "             input_sequence,\n",
    "             states):\n",
    "  \n",
    "        embeddings = self.embedding(input_sequence)\n",
    "        \n",
    "        enc_out, enc_h_state, enc_c_state = self.lstm(embeddings, initial_state = states)\n",
    "        \n",
    "        return enc_out, enc_h_state, enc_c_state\n",
    "\n",
    "    \n",
    "    def initialize_states(self,\n",
    "                          batch_size):\n",
    "  \n",
    "      return tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "486be886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 out_vocab_size,\n",
    "                 embedding_size,\n",
    "                 lstm_size,\n",
    "                 input_length):\n",
    "\n",
    "        super().__init__()\n",
    "        #Embedding layer\n",
    "        self.embedding = Embedding(out_vocab_size, embedding_size, input_length = input_length)\n",
    "        #Decoder LSTM layer\n",
    "        lstmcell = LSTMCell(lstm_size)\n",
    "        self.lstm = RNN(lstmcell, return_sequences = True, return_state = True)\n",
    "\n",
    "    def call(self,\n",
    "             input_sequence,\n",
    "             initial_states):\n",
    " \n",
    "        embeddings = self.embedding(input_sequence)\n",
    "        dec_out, dec_h_state, dec_c_state = self.lstm(embeddings, initial_state = initial_states)\n",
    "        \n",
    "        return dec_out, dec_h_state, dec_c_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47bf7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoderDecoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_vocab_size,\n",
    "                 output_vocab_size,\n",
    "                 lstm_size,\n",
    "                 embedding_size,\n",
    "                 encoder_input_length,\n",
    "                 decoder_input_length,\n",
    "                 batch_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder = Encoder(input_vocab_size,embedding_size,lstm_size,encoder_input_length)\n",
    "        self.decoder = Decoder(output_vocab_size,embedding_size,lstm_size,decoder_input_length)\n",
    "        self.dense = Dense(output_vocab_size)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        encoder_input = inputs[0]\n",
    "        decoder_input = inputs[1]\n",
    "        initial_states = self.encoder.initialize_states(tf.shape(encoder_input)[0])\n",
    "        enc_out, enc_h_state, enc_c_state = self.encoder(encoder_input,initial_states)\n",
    "        dec_out, dec_h_state, dec_c_state = self.decoder(decoder_input,[enc_h_state,enc_c_state])\n",
    "        ita = self.dense(dec_out)\n",
    "        \n",
    "        return ita\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05f00faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-896af348ef468554\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-896af348ef468554\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -rf ./logs/\n",
    "logdir = os.path.join('logs', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "%tensorboard --logdir $logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0dd8591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "#defining the model\n",
    "vanilla_encoder_decoder = encoderDecoder(encoder_vocab_size,\n",
    "                                          decoder_vocab_size,\n",
    "                                          350,\n",
    "                                         350,\n",
    "                                         encoder_input_train.shape[-1],\n",
    "                                          decoder_input_train.shape[-1],\n",
    "                                          batch_size = 64\n",
    "                                        )\n",
    "#defining callbacks\n",
    "callbacks = [\n",
    "             \n",
    "             tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0.01, patience = 1)]\n",
    "\n",
    "#              tf.keras.callbacks.ModelCheckpoint('vanilla_enc_dec_{epoch}', monitor = 'val_loss', save_best_only  = True,save_format=\"tf\") ]\n",
    "#compiling the model\n",
    "vanilla_encoder_decoder.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002),\n",
    "                                loss = 'sparse_categorical_crossentropy',\n",
    "                               metrics=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "acf4a877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441/441 [==============================] - 968s 2s/step - loss: 0.2178 - val_loss: 0.3863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e75fd50d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_data_generator = dataLoader(encoder_input_train, decoder_input_train, decoder_output_train, batch_size)\n",
    "val_data_generator = dataLoader(encoder_input_cv, decoder_input_cv, decoder_output_cv, batch_size)\n",
    "\n",
    "vanilla_encoder_decoder.fit(train_data_generator,\n",
    "                            validation_data = val_data_generator,\n",
    "                            epochs = 5,\n",
    "                            callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c333840",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_int_to_word = {decoder_word_to_int[key]:key for key in decoder_word_to_int }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "972400b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    #tokenize test sentences\n",
    "    encoder_inputs = tokenizer_encoder.texts_to_sequences([text])\n",
    "    # pad the test sentences\n",
    "    encoder_inputs = padding(encoder_inputs)\n",
    "    initial_state = vanilla_encoder_decoder.layers[0].initialize_states(1)\n",
    "    enc_out, enc_h_state, enc_c_state = vanilla_encoder_decoder.layers[0](encoder_inputs,initial_state)\n",
    "    decoder_states = [enc_h_state,enc_c_state]\n",
    "    # define the start of sentence for the decoder\n",
    "    decoder_initial_input = np.array([[tokenizer_decoder.word_index['<start>']]])\n",
    "    prediction = []\n",
    "    while True:\n",
    "        ## defining decoder layers\n",
    "        dec_out, dec_h_state, dec_c_state = vanilla_encoder_decoder.layers[1](decoder_initial_input,\n",
    "                                                                              initial_states=decoder_states)\n",
    "        pred_vector = vanilla_encoder_decoder.layers[2](dec_out)\n",
    "        pred_index = np.argmax(pred_vector)\n",
    "        pre_word = decoder_int_to_word[pred_index]\n",
    "        prediction.append(pre_word)\n",
    "        if pre_word == \"<end>\" or len(prediction)>=20:\n",
    "            return \" \".join(prediction)\n",
    "        \n",
    "        decoder_states = [dec_h_state,dec_c_state]\n",
    "        decoder_initial_input = np.array([[pred_index]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6962afc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Italian sentence: <start> non ã¨ il nostro problema ora <end>\n",
      "Actual Translation: that is not our problem now <end>\n",
      "Predicted Translation: that is not our problem now <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> perchã© state cercando di perdere peso <end>\n",
      "Actual Translation: why are you trying to lose weight <end>\n",
      "Predicted Translation: why are you trying to lose weight <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> lasciatemi dire perchã© a me non piace tom <end>\n",
      "Actual Translation: let me tell you why i do not like tom <end>\n",
      "Predicted Translation: let me tell me how to do that and do that <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> pensavo che tom non l avrebbe mai piã¹ rivista <end>\n",
      "Actual Translation: i thought tom would never see you again <end>\n",
      "Predicted Translation: i thought tom would never take the gun <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> tom andã² via <end>\n",
      "Actual Translation: tom went away <end>\n",
      "Predicted Translation: tom went away <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> ãˆ rischioso per te andare in quella zona da solo <end>\n",
      "Actual Translation: it is risky for you to go into that area alone <end>\n",
      "Predicted Translation: it is going to end for the summer <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> facciamo questo piã¹ tardi <end>\n",
      "Actual Translation: let is do this later <end>\n",
      "Predicted Translation: do we eat this later <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> sono pronto <end>\n",
      "Actual Translation: i am attentive <end>\n",
      "Predicted Translation: i am ready <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> tom mi ha detto che era pronto <end>\n",
      "Actual Translation: tom told me he was ready <end>\n",
      "Predicted Translation: tom told me that he was ready <end>\n",
      "\n",
      "==================================================\n",
      "\n",
      "Italian sentence: <start> lui ha iniziato a cantare <end>\n",
      "Actual Translation: he started to sing <end>\n",
      "Predicted Translation: he began to sing <end>\n",
      "\n",
      "==================================================\n",
      "Mean Bleu Score = 0.4100179743312485\n"
     ]
    }
   ],
   "source": [
    "bleu_score = []\n",
    "print(\"=\" * 50)     \n",
    "#prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f89b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
